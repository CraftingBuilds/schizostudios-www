{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb5281c5-c2f1-4748-bf59-91e47b2f35d6",
   "metadata": {},
   "source": [
    "Cell 1 - Imports and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88cb8d24-2d30-4aa6-8bec-878455c35bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init] MoviePy detected: 1.0.3\n",
      "[Init] Librosa detected.\n",
      "[Init] CairoSVG detected.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import wave\n",
    "import struct\n",
    "from io import BytesIO\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Widgets for uploads & controls\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# --- MoviePy detection -------------------------------------------------------\n",
    "HAS_MOVIEPY = False\n",
    "HAS_LIBROSA = False\n",
    "HAS_SVG = False\n",
    "\n",
    "try:\n",
    "    from moviepy.editor import VideoClip, AudioFileClip\n",
    "    import moviepy\n",
    "    HAS_MOVIEPY = True\n",
    "    print(f\"[Init] MoviePy detected: {moviepy.__version__}\")\n",
    "except Exception as e:\n",
    "    print(f\"[Warning] MoviePy unavailable: {e}\")\n",
    "\n",
    "try:\n",
    "    import librosa\n",
    "    HAS_LIBROSA = True\n",
    "    print(\"[Init] Librosa detected.\")\n",
    "except Exception as e:\n",
    "    print(f\"[Warning] Librosa unavailable: {e}\")\n",
    "\n",
    "try:\n",
    "    import cairosvg\n",
    "    HAS_SVG = True\n",
    "    print(\"[Init] CairoSVG detected.\")\n",
    "except Exception as e:\n",
    "    print(f\"[Warning] CairoSVG unavailable: {e}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Config\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# IMPORTANT: we symlinked geometry → ~/projects/LightCraft/geometry\n",
    "#   cd /var/www/schizo-studios/notebooks\n",
    "#   ln -s ~/projects/LightCraft/geometry geometry\n",
    "GEOMETRY_DIR = \"geometry\"\n",
    "\n",
    "SACRED_NUMBER = 7      # numerology cycle (1–7)\n",
    "ASTRO_CYCLES = 12      # zodiac cycle\n",
    "RENDER_FPS = 30\n",
    "MOCK_DURATION_S = 30.0\n",
    "\n",
    "ZODIAC_ARCHETYPES = [\n",
    "    {\"sign\": \"Aries\",       \"element\": \"Fire\",  \"color\": (200,  50,  50)},\n",
    "    {\"sign\": \"Taurus\",      \"element\": \"Earth\", \"color\": ( 50, 150,  50)},\n",
    "    {\"sign\": \"Gemini\",      \"element\": \"Air\",   \"color\": (150, 150, 200)},\n",
    "    {\"sign\": \"Cancer\",      \"element\": \"Water\", \"color\": (100, 150, 200)},\n",
    "    {\"sign\": \"Leo\",         \"element\": \"Fire\",  \"color\": (255, 160,   0)},\n",
    "    {\"sign\": \"Virgo\",       \"element\": \"Earth\", \"color\": (100, 100, 100)},\n",
    "    {\"sign\": \"Libra\",       \"element\": \"Air\",   \"color\": (200, 100, 200)},\n",
    "    {\"sign\": \"Scorpio\",     \"element\": \"Water\", \"color\": ( 80,   0, 120)},\n",
    "    {\"sign\": \"Sagittarius\", \"element\": \"Fire\",  \"color\": (180,  80,   0)},\n",
    "    {\"sign\": \"Capricorn\",   \"element\": \"Earth\", \"color\": ( 50,  50,  80)},\n",
    "    {\"sign\": \"Aquarius\",    \"element\": \"Air\",   \"color\": (  0, 150, 200)},\n",
    "    {\"sign\": \"Pisces\",      \"element\": \"Water\", \"color\": (100, 100, 255)},\n",
    "]\n",
    "\n",
    "RESOLUTIONS = {\n",
    "    1: (1920, 1080, \"16:9 (HD/YouTube)\"),\n",
    "    2: (3840, 2160, \"16:9 (4K UHD)\"),\n",
    "    3: (1080, 1920, \"9:16 (Vertical/Shorts)\"),\n",
    "    4: (1080, 1080, \"1:1 (Square/Instagram)\"),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414e4759-4a52-4b33-8197-5f346ad0a9c9",
   "metadata": {},
   "source": [
    "Cell 2 - Helpers + Geometry Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01f8cca4-0b2f-4333-b331-c9a1bca59d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''\n",
    "<style>\n",
    "div.input {display:none;}\n",
    "</style>\n",
    "''')\n",
    "\n",
    "def _interpolate_color(c1: Tuple[int,int,int], c2: Tuple[int,int,int], blend: float) -> Tuple[int,int,int]:\n",
    "    blend = max(0.0, min(1.0, blend))\n",
    "    return (\n",
    "        int(c1[0] + (c2[0] - c1[0]) * blend),\n",
    "        int(c1[1] + (c2[1] - c1[1]) * blend),\n",
    "        int(c1[2] + (c2[2] - c1[2]) * blend),\n",
    "    )\n",
    "\n",
    "def _ensure_geometry_dir(geometry_dir: str) -> List[str]:\n",
    "    if not HAS_SVG:\n",
    "        raise RuntimeError(\"You must install `cairosvg` and `Pillow` for SVG support (pip install cairosvg pillow).\")\n",
    "\n",
    "    if not os.path.isdir(geometry_dir):\n",
    "        raise RuntimeError(f\"Geometry directory not found: {geometry_dir}\")\n",
    "\n",
    "    files = [\n",
    "        os.path.join(geometry_dir, f)\n",
    "        for f in sorted(os.listdir(geometry_dir))\n",
    "        if f.lower().endswith(\".svg\")\n",
    "    ]\n",
    "    if not files:\n",
    "        raise RuntimeError(f\"No .svg files found in {geometry_dir}\")\n",
    "\n",
    "    print(f\"[Init] Loaded {len(files)} sacred geometry SVGs from {geometry_dir}\")\n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b71f96-df38-4f60-a2c4-1148f9827f01",
   "metadata": {},
   "source": [
    "Cell 3 - SacredAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dad3eed-64a5-482c-9088-be1f1f265c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SacredAnalyzer:\n",
    "    \"\"\"Audio → sacred visual parameters using Librosa features.\"\"\"\n",
    "\n",
    "    def __init__(self, audio_data: np.ndarray, sample_rate: int, duration_s: float):\n",
    "        self.audio_data = audio_data\n",
    "        self.sample_rate = sample_rate\n",
    "        self.duration_s = duration_s\n",
    "\n",
    "        self.beat_times = np.array([])\n",
    "        self.tonnetz = np.array([])\n",
    "        self.frame_times = np.array([])\n",
    "        self.phrase_boundaries = np.array([])\n",
    "        self._current_cycle = 0\n",
    "\n",
    "        if HAS_LIBROSA:\n",
    "            self._pre_analyze()\n",
    "        else:\n",
    "            print(\"[Analyzer] Librosa not installed; running in minimal mode.\")\n",
    "\n",
    "    def _pre_analyze(self):\n",
    "        if self.audio_data.size == 0:\n",
    "            print(\"[Analyzer] No audio data to analyze.\")\n",
    "            return\n",
    "\n",
    "        # Beat tracking\n",
    "        _, self.beat_times = librosa.beat.beat_track(\n",
    "            y=self.audio_data, sr=self.sample_rate, units=\"time\"\n",
    "        )\n",
    "        print(f\"[Analyzer] Beats detected: {len(self.beat_times)}\")\n",
    "\n",
    "        # Tonnetz (tonal centroid)\n",
    "        chroma = librosa.feature.chroma_stft(y=self.audio_data, sr=self.sample_rate)\n",
    "        self.tonnetz = librosa.feature.tonnetz(chroma=chroma)\n",
    "        self.frame_times = librosa.frames_to_time(\n",
    "            np.arange(self.tonnetz.shape[1]), sr=self.sample_rate\n",
    "        )\n",
    "\n",
    "        # Phrase boundaries via RMS\n",
    "        rms = librosa.feature.rms(y=self.audio_data)[0]\n",
    "        median_rms = np.median(rms)\n",
    "        frames = librosa.util.peak_pick(\n",
    "            rms, pre_max=20, post_max=20,\n",
    "            pre_avg=10, post_avg=10,\n",
    "            delta=median_rms * 0.5,\n",
    "            wait=10\n",
    "        )\n",
    "        self.phrase_boundaries = librosa.frames_to_time(frames, sr=self.sample_rate)\n",
    "        print(f\"[Analyzer] Phrase boundaries: {len(self.phrase_boundaries)}\")\n",
    "\n",
    "    def get_params(self, t: float) -> Dict[str, Any]:\n",
    "        if self.phrase_boundaries.size > 0:\n",
    "            for b in self.phrase_boundaries:\n",
    "                if b > (t - 1.0/RENDER_FPS) and b <= t:\n",
    "                    self._current_cycle = (self._current_cycle % SACRED_NUMBER) + 1\n",
    "                    break\n",
    "        layers = self._current_cycle if self._current_cycle > 0 else 1\n",
    "\n",
    "        # Tonnetz → consonance/dissonance\n",
    "        if HAS_LIBROSA and self.tonnetz.size > 0:\n",
    "            idx = np.searchsorted(self.frame_times, t, side=\"left\")\n",
    "            idx = min(idx, self.tonnetz.shape[1] - 1)\n",
    "            curr = self.tonnetz[:, idx]\n",
    "            if idx > 0:\n",
    "                prev = self.tonnetz[:, idx - 1]\n",
    "                change = np.linalg.norm(curr - prev)\n",
    "            else:\n",
    "                change = 0.0\n",
    "            max_change = 0.8\n",
    "            dissonance = min(1.0, change / max_change)\n",
    "            consonance = 1.0 - dissonance\n",
    "        else:\n",
    "            consonance = 1.0\n",
    "            dissonance = 0.0\n",
    "\n",
    "        # Local amplitude\n",
    "        start = int(t * self.sample_rate)\n",
    "        end = min(start + self.sample_rate // RENDER_FPS, len(self.audio_data))\n",
    "        if end > start:\n",
    "            chunk = self.audio_data[start:end]\n",
    "            peak = float(np.max(np.abs(chunk))) if chunk.size > 0 else 0.0\n",
    "        else:\n",
    "            peak = 0.0\n",
    "        geom_intensity = min(1.0, peak * 5.0)\n",
    "\n",
    "        # Beat pulse\n",
    "        pulse = 0.0\n",
    "        if self.beat_times.size > 0:\n",
    "            idx = np.argmin(np.abs(self.beat_times - t))\n",
    "            dt = abs(self.beat_times[idx] - t)\n",
    "            tol = 0.1\n",
    "            if dt < tol:\n",
    "                pulse = 1.0 - (dt / tol)\n",
    "\n",
    "        time_ratio = t / self.duration_s if self.duration_s > 0 else 0.0\n",
    "        astro_phase = (time_ratio * ASTRO_CYCLES) % ASTRO_CYCLES\n",
    "\n",
    "        return {\n",
    "            \"time_s\": t,\n",
    "            \"layers\": layers,\n",
    "            \"geom_intensity\": geom_intensity,\n",
    "            \"consonance\": consonance,\n",
    "            \"dissonance\": dissonance,\n",
    "            \"pulse\": pulse,\n",
    "            \"astro_phase\": astro_phase,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54b6c22-10eb-4342-9fed-1c8ee8e67f9e",
   "metadata": {},
   "source": [
    "Cell 4 - SVGVisualGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d03be908-a302-4bee-b5fe-0501921460ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVGVisualGenerator:\n",
    "    \"\"\"\n",
    "    Render sacred geometry using your SVGs with:\n",
    "    - Zodiac-based background\n",
    "    - Multi-tone radial gradient\n",
    "    - SVG overlay (rotating, breathing)\n",
    "    - Dual breathing: geometry + camera\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, width: int, height: int, svg_paths: List[str]):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.svg_paths = svg_paths\n",
    "        self.cache: Dict[str, Image.Image] = {}\n",
    "\n",
    "    def _load_svg_rgba(self, path: str) -> Image.Image:\n",
    "        if path in self.cache:\n",
    "            return self.cache[path]\n",
    "\n",
    "        with open(path, \"rb\") as f:\n",
    "            svg_bytes = f.read()\n",
    "\n",
    "        png_bytes = cairosvg.svg2png(\n",
    "            bytestring=svg_bytes,\n",
    "            output_width=self.width,\n",
    "            output_height=self.height,\n",
    "        )\n",
    "        img = Image.open(BytesIO(png_bytes)).convert(\"RGBA\")\n",
    "        self.cache[path] = img\n",
    "        return img\n",
    "\n",
    "    def _zodiac_bg_color(self, astro_phase: float) -> Tuple[int,int,int]:\n",
    "        idx1 = int(astro_phase) % ASTRO_CYCLES\n",
    "        idx2 = (idx1 + 1) % ASTRO_CYCLES\n",
    "        blend = astro_phase - idx1\n",
    "        c1 = ZODIAC_ARCHETYPES[idx1][\"color\"]\n",
    "        c2 = ZODIAC_ARCHETYPES[idx2][\"color\"]\n",
    "        return _interpolate_color(c1, c2, blend)\n",
    "\n",
    "    def _gradient_colors(self, params: Dict[str, Any]) -> Tuple[Tuple[int,int,int], Tuple[int,int,int]]:\n",
    "        astro_phase = params[\"astro_phase\"]\n",
    "        layers = params[\"layers\"]\n",
    "        intensity = params[\"geom_intensity\"]\n",
    "        pulse = params[\"pulse\"]\n",
    "\n",
    "        base_phase = (astro_phase / ASTRO_CYCLES + layers / (SACRED_NUMBER * 2.0)) % 1.0\n",
    "\n",
    "        def phase_to_rgb(p: float) -> Tuple[int,int,int]:\n",
    "            r = 0.5 + 0.5 * math.cos(2*math.pi*p)\n",
    "            g = 0.5 + 0.5 * math.cos(2*math.pi*p + 2.09)\n",
    "            b = 0.5 + 0.5 * math.cos(2*math.pi*p + 4.18)\n",
    "            return (int(r*255), int(g*255), int(b*255))\n",
    "\n",
    "        inner = phase_to_rgb(base_phase)\n",
    "        outer_phase = (base_phase + 0.15 + 0.3*pulse) % 1.0\n",
    "        outer = phase_to_rgb(outer_phase)\n",
    "\n",
    "        def scale_color(c, s):\n",
    "            return tuple(min(255, int(ch*s)) for ch in c)\n",
    "\n",
    "        bloom = 1.0 + 0.5 * intensity\n",
    "        inner = scale_color(inner, 0.9 + 0.3*bloom)\n",
    "        outer = scale_color(outer, 0.7 + 0.4*bloom)\n",
    "\n",
    "        return inner, outer\n",
    "\n",
    "    def _pick_svg_for_params(self, params: Dict[str, Any]) -> str:\n",
    "        n = len(self.svg_paths)\n",
    "        if n == 0:\n",
    "            raise RuntimeError(\"No SVGs available.\")\n",
    "\n",
    "        layers = max(1, min(SACRED_NUMBER, params[\"layers\"]))\n",
    "        astro_phase = params[\"astro_phase\"]\n",
    "\n",
    "        base_idx = (layers - 1) % n\n",
    "        offset = int(astro_phase) % n\n",
    "        idx = (base_idx + offset) % n\n",
    "        return self.svg_paths[idx]\n",
    "\n",
    "    def make_frame(self, t: float, params: Dict[str, Any]) -> np.ndarray:\n",
    "        bg_color = self._zodiac_bg_color(params[\"astro_phase\"])\n",
    "        bg = np.full((self.height, self.width, 3), bg_color, dtype=np.uint8)\n",
    "\n",
    "        svg_path = self._pick_svg_for_params(params)\n",
    "        base_img = self._load_svg_rgba(svg_path)\n",
    "\n",
    "        dissonance = params[\"dissonance\"]\n",
    "        geom_intensity = params[\"geom_intensity\"]\n",
    "        pulse = params[\"pulse\"]\n",
    "\n",
    "        base_scale = 0.9 + 0.15*geom_intensity + 0.1*pulse\n",
    "        rotation_deg = (t * 10.0 * (0.5 + dissonance)) % 360.0\n",
    "\n",
    "        # Hypnotic breathing (4–4–6–2)\n",
    "        cycle_time = 16.0\n",
    "        phase = t % cycle_time\n",
    "\n",
    "        if phase < 4.0:         # Inhale\n",
    "            breath = 1.0 + (phase / 4.0)\n",
    "            micro = 0.0\n",
    "        elif phase < 8.0:       # Hold\n",
    "            breath = 2.0\n",
    "            micro = 0.02 * math.sin(2 * math.pi * (phase - 4.0) * 1.2)\n",
    "        elif phase < 14.0:      # Exhale\n",
    "            breath = 2.0 - ((phase - 8.0) / 6.0)\n",
    "            micro = 0.0\n",
    "        else:                   # Pause\n",
    "            breath = 1.0\n",
    "            micro = 0.03 * math.sin(2 * math.pi * (phase - 14.0) * 1.5)\n",
    "\n",
    "        geometry_scale = breath + micro\n",
    "        camera_scale = breath + micro * 0.5\n",
    "\n",
    "        scale_factor = base_scale * geometry_scale\n",
    "\n",
    "        w_base, h_base = base_img.size\n",
    "        w_scaled = max(1, int(w_base * scale_factor))\n",
    "        h_scaled = max(1, int(h_base * scale_factor))\n",
    "        img_scaled = base_img.resize((w_scaled, h_scaled), resample=Image.LANCZOS)\n",
    "        img_rot = img_scaled.rotate(rotation_deg, resample=Image.BICUBIC, expand=True)\n",
    "\n",
    "        canvas = Image.new(\"RGBA\", (self.width, self.height), (0,0,0,0))\n",
    "        x = (self.width  - img_rot.size[0]) // 2\n",
    "        y = (self.height - img_rot.size[1]) // 2\n",
    "        canvas.paste(img_rot, (x, y), img_rot)\n",
    "\n",
    "        svg_rgba = np.array(canvas).astype(np.float32)\n",
    "\n",
    "        inner_color, outer_color = self._gradient_colors(params)\n",
    "\n",
    "        yy, xx = np.meshgrid(\n",
    "            np.linspace(-1.0, 1.0, self.height),\n",
    "            np.linspace(-1.0, 1.0, self.width),\n",
    "            indexing=\"ij\",\n",
    "        )\n",
    "        radius = np.sqrt(xx**2 + yy**2)\n",
    "        radius = np.clip(radius, 0.0, 1.0)\n",
    "\n",
    "        inner = np.array(inner_color, dtype=np.float32).reshape(1,1,3)\n",
    "        outer = np.array(outer_color, dtype=np.float32).reshape(1,1,3)\n",
    "        grad_rgb = inner*(1.0 - radius[...,None]) + outer*radius[...,None]\n",
    "\n",
    "        alpha = svg_rgba[..., 3:4] / 255.0\n",
    "        geom_rgb = grad_rgb * alpha\n",
    "\n",
    "        bg_f = bg.astype(np.float32)\n",
    "        out_rgb = bg_f*(1.0 - alpha) + geom_rgb\n",
    "\n",
    "        if camera_scale != 1.0:\n",
    "            h, w, _ = out_rgb.shape\n",
    "            new_w = max(1, int(w * camera_scale))\n",
    "            new_h = max(1, int(h * camera_scale))\n",
    "            frame_img = Image.fromarray(out_rgb.astype(np.uint8))\n",
    "            zoom_img = frame_img.resize((new_w, new_h), resample=Image.BICUBIC)\n",
    "            x = (new_w - w) // 2\n",
    "            y = (new_h - h) // 2\n",
    "            crop = zoom_img.crop((x, y, x + w, y + h))\n",
    "            out_rgb = np.array(crop, dtype=np.float32)\n",
    "\n",
    "        return out_rgb.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a674ff-c31c-450a-a82d-34f3aff0faa6",
   "metadata": {},
   "source": [
    "Cell 5 - LightCraft Render + basic_analyze_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4563e39-99f4-4e25-898c-f54b61eb9814",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightCraftRenderer:\n",
    "    def __init__(self, width: int, height: int, fps: int, svg_paths: List[str]):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.fps = fps\n",
    "        self.svg_paths = svg_paths\n",
    "        self.visual_gen = SVGVisualGenerator(width, height, svg_paths)\n",
    "        self.audio_data = np.array([])\n",
    "        self.sample_rate = 0\n",
    "        self.duration_s = 0.0\n",
    "\n",
    "    def _load_audio(self, path: str) -> bool:\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"[Loader] Audio not found: {path}\")\n",
    "            print(f\"          Using {MOCK_DURATION_S}s synthetic noise.\")\n",
    "            self.sample_rate = 44100\n",
    "            self.duration_s = MOCK_DURATION_S\n",
    "            n = int(self.sample_rate * self.duration_s)\n",
    "            self.audio_data = np.random.uniform(-0.8, 0.8, n).astype(np.float32)\n",
    "            return False\n",
    "\n",
    "        if not HAS_LIBROSA:\n",
    "            print(\"[Loader] Librosa not installed. Using synthetic noise.\")\n",
    "            self.sample_rate = 44100\n",
    "            self.duration_s = MOCK_DURATION_S\n",
    "            n = int(self.sample_rate * self.duration_s)\n",
    "            self.audio_data = np.random.uniform(-0.8, 0.8, n).astype(np.float32)\n",
    "            return False\n",
    "\n",
    "        print(f\"[Loader] Loading audio via Librosa: {path}\")\n",
    "        try:\n",
    "            y, sr = librosa.load(path, sr=44100)\n",
    "            self.audio_data = y\n",
    "            self.sample_rate = sr\n",
    "            self.duration_s = librosa.get_duration(y=y, sr=sr)\n",
    "            print(f\"[Loader] Duration: {self.duration_s:.2f}s\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"[Loader] Librosa failed: {e}\")\n",
    "            print(f\"          Using {MOCK_DURATION_S}s synthetic noise.\")\n",
    "            self.sample_rate = 44100\n",
    "            self.duration_s = MOCK_DURATION_S\n",
    "            n = int(self.sample_rate * self.duration_s)\n",
    "            self.audio_data = np.random.uniform(-0.8, 0.8, n).astype(np.float32)\n",
    "            return False\n",
    "\n",
    "    def render(self, audio_path: str, out_path: str):\n",
    "        if not HAS_MOVIEPY:\n",
    "            print(\"ERROR: MoviePy not installed. pip install moviepy\")\n",
    "            return\n",
    "\n",
    "        self._load_audio(audio_path)\n",
    "        analyzer = SacredAnalyzer(self.audio_data, self.sample_rate, self.duration_s)\n",
    "\n",
    "        def make_frame(t: float) -> np.ndarray:\n",
    "            params = analyzer.get_params(t)\n",
    "            frame_idx = int(t * self.fps)\n",
    "            if frame_idx % (self.fps * 5) == 0:\n",
    "                zidx = int(params[\"astro_phase\"]) % ASTRO_CYCLES\n",
    "                zsign = ZODIAC_ARCHETYPES[zidx][\"sign\"]\n",
    "                print(\n",
    "                    f\"[Frame] t={t:6.2f}s | layers={params['layers']} \"\n",
    "                    f\"| purity={params['consonance']:.2f} | zodiac={zsign}\"\n",
    "                )\n",
    "            return self.visual_gen.make_frame(t, params)\n",
    "\n",
    "        clip = VideoClip(make_frame, duration=self.duration_s).set_fps(self.fps)\n",
    "        start_t = time.time()\n",
    "\n",
    "        try:\n",
    "            audio_clip = AudioFileClip(audio_path)\n",
    "            final_clip = clip.set_audio(audio_clip)\n",
    "            print(\"[Encoder] Rendering LightCraft (with audio)...\")\n",
    "            final_clip.write_videofile(\n",
    "                out_path,\n",
    "                fps=self.fps,\n",
    "                codec=\"libx264\",\n",
    "                temp_audiofile=\"temp-audio.m4a\",\n",
    "                remove_temp=True,\n",
    "                verbose=False,\n",
    "                logger=None,\n",
    "            )\n",
    "            print(f\"[Done] Saved → {out_path} ({time.time() - start_t:.2f}s)\")\n",
    "        except Exception as e:\n",
    "            print(f\"[Encoder] Audio attach failed: {e}\")\n",
    "            fallback = out_path.replace(\".mp4\", \"_visual_only.mp4\")\n",
    "            print(\"[Encoder] Rendering visual-only fallback...\")\n",
    "            clip.write_videofile(\n",
    "                fallback,\n",
    "                fps=self.fps,\n",
    "                codec=\"libx264\",\n",
    "                verbose=False,\n",
    "                logger=None,\n",
    "            )\n",
    "            print(f\"[Done] Saved → {fallback} ({time.time() - start_t:.2f}s)\")\n",
    "\n",
    "def basic_analyze_wav(path: str) -> Dict[str, Any]:\n",
    "    if not path.lower().endswith(\".wav\"):\n",
    "        raise ValueError(\"Basic mode expects a .wav file.\")\n",
    "    try:\n",
    "        with wave.open(path, \"rb\") as wf:\n",
    "            n_channels = wf.getnchannels()\n",
    "            sw = wf.getsampwidth()\n",
    "            fr = wf.getframerate()\n",
    "            n_frames = wf.getnframes()\n",
    "            frames = wf.readframes(n_frames)\n",
    "        if sw != 2:\n",
    "            raise ValueError(\"Basic mode only supports 16-bit WAV.\")\n",
    "        fmt = f\"{n_frames * n_channels}h\"\n",
    "        audio = np.array(struct.unpack(fmt, frames), dtype=np.float32)\n",
    "        max16 = 32767.0\n",
    "        rms = float(np.sqrt(np.mean(audio**2)))\n",
    "        vol = rms / max16\n",
    "        zc = float(np.sum(np.abs(np.diff(np.sign(audio)))) / 2.0)\n",
    "        busy = zc / float(n_frames)\n",
    "        dur = n_frames / float(fr)\n",
    "        return {\"volume\": vol, \"busy\": busy, \"duration\": dur}\n",
    "    except Exception as e:\n",
    "        print(f\"[Basic] WAV analysis error: {e}\")\n",
    "        return {\"volume\": 0.0, \"busy\": 0.0, \"duration\": 10.0}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b26558-2086-4273-92af-a83245dfc62f",
   "metadata": {},
   "source": [
    "Cell 6 - Notebook UI: Upload + Resolution + Mode + Render Button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "865122b3-64ad-46bd-b6d6-9e15f3ce67a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe6366896844eef92b4f50474a76682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>LightCraft Notebook Workstation</h3>'), HTML(value='<b>1.</b> Upload audio file…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Widgets\n",
    "audio_uploader = widgets.FileUpload(\n",
    "    accept='.wav,.mp3,.m4a,.flac',\n",
    "    multiple=False,\n",
    "    description='Upload Audio'\n",
    ")\n",
    "\n",
    "mode_dropdown = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('Full LightCraft (Librosa, audio-reactive)', 'full'),\n",
    "        ('Basic WAV Visualizer (simpler, WAV only)', 'basic')\n",
    "    ],\n",
    "    value='full',\n",
    "    description='Mode:',\n",
    ")\n",
    "\n",
    "res_dropdown = widgets.Dropdown(\n",
    "    options=[(f\"{w}x{h} {desc}\", key) for key, (w,h,desc) in RESOLUTIONS.items()],\n",
    "    value=1,\n",
    "    description='Resolution:'\n",
    ")\n",
    "\n",
    "out_name = widgets.Text(\n",
    "    value='lightcraft_output.mp4',\n",
    "    description='Output:',\n",
    "    layout=widgets.Layout(width='50%')\n",
    ")\n",
    "\n",
    "run_button = widgets.Button(\n",
    "    description='Render LightCraft',\n",
    "    button_style='success'\n",
    ")\n",
    "\n",
    "log_output = widgets.Output()\n",
    "\n",
    "controls = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>LightCraft Notebook Workstation</h3>\"),\n",
    "    widgets.HTML(\"<b>1.</b> Upload audio file\"),\n",
    "    audio_uploader,\n",
    "    widgets.HTML(\"<b>2.</b> Choose mode & resolution\"),\n",
    "    mode_dropdown,\n",
    "    res_dropdown,\n",
    "    widgets.HTML(\"<b>3.</b> Output filename\"),\n",
    "    out_name,\n",
    "    run_button,\n",
    "    log_output\n",
    "])\n",
    "\n",
    "display(controls)\n",
    "\n",
    "def handle_render_clicked(b):\n",
    "    with log_output:\n",
    "        clear_output()\n",
    "        print(\"[UI] Starting LightCraft render...\")\n",
    "\n",
    "        # Check geometry dir\n",
    "        try:\n",
    "            svg_paths = _ensure_geometry_dir(GEOMETRY_DIR)\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] {e}\")\n",
    "            return\n",
    "\n",
    "        # Check audio upload\n",
    "        if len(audio_uploader.value) == 0:\n",
    "            print(\"[Error] Please upload an audio file first.\")\n",
    "            return\n",
    "\n",
    "        # Save uploaded audio to a temp file\n",
    "        upload_info = list(audio_uploader.value.values())[0]\n",
    "        audio_bytes = upload_info['content']\n",
    "        original_name = upload_info['metadata']['name']\n",
    "        temp_audio_path = os.path.join(os.getcwd(), f\"uploaded_{original_name}\")\n",
    "\n",
    "        with open(temp_audio_path, 'wb') as f:\n",
    "            f.write(audio_bytes)\n",
    "\n",
    "        print(f\"[UI] Saved uploaded audio to: {temp_audio_path}\")\n",
    "\n",
    "        # Resolution\n",
    "        res_key = res_dropdown.value\n",
    "        width, height, _ = RESOLUTIONS[res_key]\n",
    "\n",
    "        # Output path\n",
    "        output_path = out_name.value.strip()\n",
    "        if not output_path:\n",
    "            output_path = \"lightcraft_output.mp4\"\n",
    "        if not output_path.lower().endswith(\".mp4\"):\n",
    "            output_path += \".mp4\"\n",
    "\n",
    "        mode = mode_dropdown.value\n",
    "\n",
    "        if mode == 'full':\n",
    "            print(\"[UI] Running Full LightCraft mode...\")\n",
    "            renderer = LightCraftRenderer(width, height, RENDER_FPS, svg_paths)\n",
    "            renderer.render(temp_audio_path, output_path)\n",
    "        else:\n",
    "            print(\"[UI] Running Basic WAV Visualizer mode...\")\n",
    "            if not temp_audio_path.lower().endswith(\".wav\"):\n",
    "                print(\"[Error] Basic mode currently only supports .wav files.\")\n",
    "                return\n",
    "\n",
    "            stats = basic_analyze_wav(temp_audio_path)\n",
    "            duration = max(5.0, stats[\"duration\"])\n",
    "            vg = SVGVisualGenerator(width, height, svg_paths)\n",
    "\n",
    "            def make_frame(t: float) -> np.ndarray:\n",
    "                time_ratio = t / duration\n",
    "                astro_phase = (time_ratio * ASTRO_CYCLES) % ASTRO_CYCLES\n",
    "                layers = 1 + int(time_ratio * SACRED_NUMBER)\n",
    "                geom_intensity = min(1.0, stats[\"volume\"] * 2.5)\n",
    "                pulse = abs(math.sin(t * 2.0))\n",
    "                params = {\n",
    "                    \"time_s\": t,\n",
    "                    \"layers\": layers,\n",
    "                    \"geom_intensity\": geom_intensity,\n",
    "                    \"consonance\": 0.8,\n",
    "                    \"dissonance\": 0.2,\n",
    "                    \"pulse\": pulse,\n",
    "                    \"astro_phase\": astro_phase,\n",
    "                }\n",
    "                return vg.make_frame(t, params)\n",
    "\n",
    "            if not HAS_MOVIEPY:\n",
    "                print(\"ERROR: MoviePy not installed. pip install moviepy\")\n",
    "                return\n",
    "\n",
    "            clip = VideoClip(make_frame, duration=duration).set_fps(RENDER_FPS)\n",
    "            print(\"[Basic] Rendering hypnotic LightCraft (no audio sync)...\")\n",
    "            clip.write_videofile(\n",
    "                output_path,\n",
    "                fps=RENDER_FPS,\n",
    "                codec=\"libx264\",\n",
    "                verbose=False,\n",
    "                logger=None,\n",
    "            )\n",
    "            print(f\"[Basic] Saved → {output_path}\")\n",
    "\n",
    "        print(\"[UI] Done.\")\n",
    "\n",
    "run_button.on_click(handle_render_clicked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ebd4cb-033e-44ce-8abc-5a4e7db4758b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
